{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb12e342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aae251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(file_name):\n",
    "    data = pd.read_csv(file_name, delimiter=' ', header=None)\n",
    "    data = data.drop(data.columns[-1], axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e1069fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [get_df(file) for file in ['origCode.mutex','sameSleep0.4.mutex','countingLoop.mutex','dec0.05.mutex',\n",
    "                                    'out0.4.mutex','dec0.8.mutex','inc0.05.mutex','inc0.4.mutex','inc0.8.mutex',\n",
    "                                    'out3threads.mutex','out4threads.mutex','out5threads.mutex']]#,'outcountSample3.mutex',\n",
    "                                    #'outsample3.mutex']]\n",
    "\n",
    "# Some extra data that should be deleted for these sets\n",
    "frames[10] = frames[10].dropna()\n",
    "frames[11] = frames[11].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b730559",
   "metadata": {},
   "source": [
    "## Formatting examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fdb2e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "orig = pd.read_csv('origCode.mutex', delimiter=' ', header=None)\n",
    "orig = orig.drop(orig.columns[-1], axis=1).dropna() # Extra NaN column for some reason (and dropna for issue fix)\n",
    "orig # 0 0 indicates no error, anything else indicates error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3402a974",
   "metadata": {},
   "outputs": [],
   "source": [
    "fails = orig[(orig != 0).any(axis=1)]\n",
    "pd.set_option('display.max_rows', None)\n",
    "fails # Maybe all errors are 1 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826619ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fails) / len(orig) # Error rate for a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1531ce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(fails.index, color='skyblue', edgecolor='black', range=(0, len(orig)))\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Error Frequency')\n",
    "plt.title('Error Frequency over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b72c829",
   "metadata": {},
   "source": [
    "## Errors with respect to iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a10936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_freq_time(data, title, subplot):\n",
    "    errors = data[(data != 0).any(axis=1)] # Not 0 0 (error)\n",
    "    subplot.hist(errors.index, range=(0, len(data)), edgecolor='black')\n",
    "    subplot.set_title(title)\n",
    "    subplot.set_xlabel('Iteration')\n",
    "    subplot.set_ylabel('Errors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2b567a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 4, figsize=(16, 12))\n",
    "axs = axs.flatten()\n",
    "\n",
    "names = ['Original', 'Inc/Dec 0.4', 'Counting Loop', 'Decrement 0.05', 'Decrement 0.4', 'Decrement 0.8', 'Increment 0.05',\n",
    "         'Increment 0.4', 'Increment 0.8', '3 Threads', '4 Threads', '5 Threads']\n",
    "for i in range(12):\n",
    "    plot_error_freq_time(frames[i], names[i], axs[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af91b4b",
   "metadata": {},
   "source": [
    "There seems to be a bit of a dip in the error quantities at about the midpoint of execution in some cases, though not in all. The distributions seem to be very similar in all cases when the number of samples is almost equal (the varying decrement trials show this well), but when the sample size differs the distributions tend to differ greatly. (Sample size is the max value on the iteration axis.) Maybe another factor such as CPU load is significant in causing differences, but we do not have that data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487b36d3",
   "metadata": {},
   "source": [
    "## Error rate with respect to varied factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bdfcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_rate(data, drop=False):\n",
    "    return len(data[(data != 0).any(axis=1)]) / len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905be614",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Loop': [False, False, True, False, False, False, False, False, False, False, False, False],\n",
    "    'IncrementSleep': [0.1, 0.4, 0.1, 0.1, 0.1, 0.1, 0.05, 0.4, 0.8, 0.1, 0.1, 0.1],\n",
    "    'DecrementSleep': [0.2, 0.4, 0.2, 0.05, 0.4, 0.8, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2],\n",
    "    'Threads': [2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4, 5],\n",
    "    'ErrorRate': [error_rate(f) for f in frames],\n",
    "    'Samples': [len(f) for f in frames]\n",
    "}\n",
    "\n",
    "data = pd.DataFrame(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1544a2",
   "metadata": {},
   "source": [
    "### Individual predictors of error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e127e048",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axs = axs.flatten()\n",
    "\n",
    "axs[0].scatter(data['IncrementSleep'], data['ErrorRate'])\n",
    "axs[0].set_xlabel('Increment Sleep')\n",
    "axs[0].set_ylabel('Error Rate')\n",
    "\n",
    "axs[1].scatter(data['DecrementSleep'], data['ErrorRate'])\n",
    "axs[1].set_xlabel('Decrement Sleep')\n",
    "axs[1].set_ylabel('Error Rate')\n",
    "\n",
    "axs[2].scatter(data['Threads'], data['ErrorRate'])\n",
    "axs[2].set_xlabel('Threads')\n",
    "axs[2].set_ylabel('Error Rate')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4384a480",
   "metadata": {},
   "source": [
    "Individually, error rate doesn't seem to vary much with respect to increment sleep or decrement sleep (extreme values here correspond to differing thread quantities). However, it seems that as the number of threads increases, so does error rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a8150f",
   "metadata": {},
   "source": [
    "### Aggregated predictors of error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbcff3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_fit = ols('ErrorRate ~ IncrementSleep + DecrementSleep + Threads', data=data).fit()\n",
    "print(lm_fit.params)\n",
    "print(\"R^2 value:\",lm_fit.rsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89523f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_fit_reduced = ols('ErrorRate ~ Threads', data=data).fit()\n",
    "\n",
    "anova_results = sm.stats.anova_lm(lm_fit_reduced, lm_fit)\n",
    "\n",
    "anova_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2574b83",
   "metadata": {},
   "source": [
    "Testing the hypothesis that the model with just the number of threads predicting error rate is significant, the F-test comparing the full model (containing increment section sleep, decrement section sleep, and number of threads) with the reduced model (only containing number of threads as a predictor) yielded a p-value of 0.444. This indicates that we cannot say at any reasonable significance level that increment section sleep or decrement section sleep are significant in determining error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323ae2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lm_fit_reduced.params)\n",
    "print(\"R^2 value:\",lm_fit_reduced.rsquared)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6e8c6f",
   "metadata": {},
   "source": [
    "Our final linear model for predicting error rate is $y=0.000756x-0.001331$, where $y$ is the error rate and $x$ is the number of threads. The high $R^2$ value of $0.959$ indicates that our model is effective at predicting error rate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
